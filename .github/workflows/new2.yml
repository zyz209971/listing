name: æ™ºèƒ½æŠ“å–ç¿»è¯‘

on:
  workflow_dispatch:
    inputs:
      url:
        description: '1688å•†å“è¯¦æƒ…é¡µURL'
        required: true
        default: 'https://detail.1688.com/offer/'

jobs:
  smart-scrape:
    runs-on: ubuntu-latest
    
    steps:
      # æ³¨æ„ï¼šè¿™é‡Œå¿…é¡»æ˜¯çŸ­æ¨ªçº¿"-"ï¼Œä¸æ˜¯"â—¦"
      - name: æ£€æŸ¥URLæœ‰æ•ˆæ€§
        run: |
          if [[ ! "${{ github.event.inputs.url }}" =~ ^https://detail\.1688\.com/.* ]]; then
            echo "é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„1688å•†å“è¯¦æƒ…é¡µURL"
            exit 1
          fi
          echo "âœ… URLéªŒè¯é€šè¿‡ï¼š${{ github.event.inputs.url }}"
          
      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: å®‰è£…Pythonä¾èµ–
        run: |
          pip install googletrans==4.0.0-rc1
          pip install beautifulsoup4
          pip install lxml
          
      - name: æŠ“å–ç½‘é¡µå†…å®¹
        id: scrape
        run: |
          echo "ğŸŒ æ­£åœ¨æŠ“å–: ${{ github.event.inputs.url }}"
          
          # ä½¿ç”¨æ›´çœŸå®çš„æµè§ˆå™¨è¯·æ±‚å¤´
          curl -s -L "${{ github.event.inputs.url }}" \
            -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36' \
            -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' \
            -H 'Accept-Language: zh-CN,zh;q=0.9,en;q=0.8' \
            -H 'Accept-Encoding: gzip, deflate, br' \
            -H 'Connection: keep-alive' \
            -H 'Upgrade-Insecure-Requests: 1' \
            -H 'Cache-Control: max-age=0' \
            --compressed \
            -o page.html
          
          if [ ! -s page.html ]; then
            echo "âŒ é”™è¯¯ï¼šé¡µé¢æŠ“å–å¤±è´¥ï¼Œå¯èƒ½è¢«åçˆ¬è™«"
            exit 1
          fi
          
          echo "âœ… é¡µé¢æŠ“å–æˆåŠŸï¼Œå¤§å°: $(wc -c < page.html) å­—èŠ‚"
          
      - name: å¤„ç†æ•°æ®
        id: process
        run: |
          cat > process.py << 'EOF'
          import re
          import json
          from html import unescape
          
          def read_html_file(filename):
              """è¯»å–HTMLæ–‡ä»¶ï¼Œå°è¯•ä¸åŒç¼–ç """
              try:
                  with open(filename, 'r', encoding='utf-8') as f:
                      return f.read()
              except:
                  try:
                      with open(filename, 'r', encoding='gbk', errors='ignore') as f:
                          return f.read()
                  except:
                      with open(filename, 'r', encoding='gb2312', errors='ignore') as f:
                          return f.read()
          
          def clean_html_tags(text):
              """æ¸…ç†HTMLæ ‡ç­¾å’Œå®ä½“"""
              if not text:
                  return ""
              text = re.sub(r'<[^>]+>', ' ', text)
              text = unescape(text)
              text = re.sub(r'\s+', ' ', text).strip()
              return text
          
          def extract_title(html):
              """ä»HTMLä¸­æå–é¡µé¢æ ‡é¢˜"""
              patterns = [
                  r'<title[^>]*>(.*?)</title>',
                  r'<meta\s+property="og:title"\s+content="([^"]+)"',
                  r'<meta\s+name="title"\s+content="([^"]+)"',
                  r'"subject"\s*:\s*"([^"]+)"',
                  r'"title"\s*:\s*"([^"]+)"'
              ]
              
              for pattern in patterns:
                  match = re.search(pattern, html, re.IGNORECASE | re.DOTALL)
                  if match:
                      title = match.group(1)
                      title = clean_html_tags(title)
                      if title and len(title) > 3:
                          return title
              
              # å°è¯•ä»h1æ ‡ç­¾æå–
              h1_match = re.search(r'<h1[^>]*>(.*?)</h1>', html, re.IGNORECASE | re.DOTALL)
              if h1_match:
                  return clean_html_tags(h1_match.group(1))
              
              # å°è¯•ä»offer_titleç±»æå–
              offer_match = re.search(r'class="offer-title"[^>]*>(.*?)</', html, re.IGNORECASE | re.DOTALL)
              if offer_match:
                  return clean_html_tags(offer_match.group(1))
              
              return "æœªæ‰¾åˆ°æ ‡é¢˜"
          
          def extract_attributes(html):
              """æå–å•†å“å±æ€§"""
              attributes = {}
              
              # ä»è¡¨æ ¼ä¸­æå–
              table_pattern = r'<table[^>]*class="[^"]*offer-table[^"]*"[^>]*>(.*?)</table>'
              table_match = re.search(table_pattern, html, re.IGNORECASE | re.DOTALL)
              if table_match:
                  table_html = table_match.group(1)
                  tr_matches = re.findall(r'<tr[^>]*>(.*?)</tr>', table_html, re.IGNORECASE | re.DOTALL)
                  
                  for tr in tr_matches:
                      th_match = re.search(r'<th[^>]*>(.*?)</th>', tr, re.IGNORECASE | re.DOTALL)
                      td_match = re.search(r'<td[^>]*>(.*?)</td>', tr, re.IGNORECASE | re.DOTALL)
                      
                      if th_match and td_match:
                          key = clean_html_tags(th_match.group(1)).strip('ï¼š:')
                          value = clean_html_tags(td_match.group(1))
                          if key and value:
                              attributes[key] = value
              
              # ä»dlæ ‡ç­¾ä¸­æå–
              if len(attributes) < 3:
                  dl_pattern = r'<dl[^>]*class="[^"]*params[^"]*"[^>]*>(.*?)</dl>'
                  dl_match = re.search(dl_pattern, html, re.IGNORECASE | re.DOTALL)
                  
                  if dl_match:
                      dl_html = dl_match.group(1)
                      dt_matches = re.findall(r'<dt[^>]*>(.*?)</dt>\s*<dd[^>]*>(.*?)</dd>', dl_html, re.IGNORECASE | re.DOTALL)
                      
                      for dt_content, dd_content in dt_matches:
                          key = clean_html_tags(dt_content).strip('ï¼š:')
                          value = clean_html_tags(dd_content)
                          if key and value:
                              attributes[key] = value
              
              # å¦‚æœè¿˜æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»æ›´é€šç”¨çš„ç»“æ„ä¸­æå–
              if len(attributes) < 3:
                  # å°è¯•åŒ¹é…ç±»ä¼¼ "å±æ€§å: å±æ€§å€¼" çš„æ¨¡å¼
                  prop_patterns = [
                      r'<li[^>]*>\s*<span[^>]*>(.*?)</span>\s*<em[^>]*>(.*?)</em>\s*</li>',
                      r'<div[^>]*class="[^"]*param[^"]*"[^>]*>.*?<span[^>]*>(.*?)</span>.*?<span[^>]*>(.*?)</span>',
                  ]
                  
                  for pattern in prop_patterns:
                      matches = re.findall(pattern, html, re.IGNORECASE | re.DOTALL)
                      for key, value in matches:
                          key = clean_html_tags(key).strip('ï¼š:')
                          value = clean_html_tags(value)
                          if key and value:
                              attributes[key] = value
              
              return attributes
          
          def remove_brand_info(text):
              """åˆ é™¤å“ç‰Œä¿¡æ¯ï¼Œä¿ç•™æœºèŠ¯å“ç‰Œ"""
              if not text:
                  return text
              
              # ä¿æŠ¤æœºèŠ¯å“ç‰Œ
              movement_brands = [
                  'miyota', 'Miyota', 'MIYOTA', 'è¥¿é“åŸæœºèŠ¯', 'citizenæœºèŠ¯',
                  'seiko', 'Seiko', 'SEIKO', 'ç²¾å·¥æœºèŠ¯', 'nh35', 'nh36', '4r36', '6r15', 
                  'eta', 'ETA', 'ç‘å£«æœºèŠ¯', 'swiss', 'Swiss', 'SWISS',
                  'ronda', 'Ronda', 'RONDA', 'isa', 'ISA', 'pc21', 'pc32',
                  'æµ·é¸¥', 'SeaGull', 'seagull', 'åŒ—äº¬', 'beijing', 'ä¸Šæµ·', 'shanghai'
              ]
              
              movement_placeholders = {}
              for movement in movement_brands:
                  if movement in text.lower():
                      placeholder = f"__MOV_{movement.upper().replace(' ', '_')}__"
                      text = re.sub(re.escape(movement), placeholder, text, flags=re.IGNORECASE)
                      movement_placeholders[placeholder] = movement
              
              # åˆ é™¤å“ç‰Œç›¸å…³æ¨¡å¼
              brand_patterns = [
                  r'(å“ç‰Œ|ç‰Œå­|brand|å•†æ ‡|å‚ç‰Œ|å‚å•†|å‚å®¶|åˆ¶é€ å•†|ç”Ÿäº§å•†|å‡ºå“|åˆ¶ä½œ)[:ï¼š\s]*[^\s,ï¼Œã€‚!ï¼?ï¼Ÿ;ï¼›ã€]{1,20}',
                  r'(ç±»ä¼¼|ä»¿|å¤åˆ»|åŒæ¬¾|é£æ ¼|æ¬¾å¼|è®¾è®¡)[\s\-]*[^\s,ï¼Œã€‚!ï¼?ï¼Ÿ;ï¼›ã€]{1,15}[:ï¼š\s]*[^\s,ï¼Œã€‚!ï¼?ï¼Ÿ;ï¼›ã€]{1,20}',
                  r'(logo|æ ‡å¿—|æ ‡è¯†|å•†æ ‡|æ ‡å¾½|å¾½æ ‡|å°è®°|åˆ»å­—|é›•åˆ»|é•Œåˆ»)[:ï¼š\s]*[^\s,ï¼Œã€‚!ï¼?ï¼Ÿ;ï¼›ã€]{1,20}',
                  r'(åŸå•|å°¾å•|å¤–è´¸|å‡ºå£|è®¢å•|ä½™å•|åº“å­˜|æ’¤æŸœ|ä¸“æŸœ)[\s\-]*[^\s,ï¼Œã€‚!ï¼?ï¼Ÿ;ï¼›ã€]{0,15}',
                  r'[^\s,ï¼Œã€‚!ï¼?ï¼Ÿ;ï¼›ã€]{1,10}ç‰Œ(?:\s+[^\s,ï¼Œã€‚!ï¼?ï¼Ÿ;ï¼›ã€]{0,10})?',
              ]
              
              for pattern in brand_patterns:
                  text = re.sub(pattern, '', text, flags=re.IGNORECASE)
              
              # æ¢å¤æœºèŠ¯å“ç‰Œ
              for placeholder, movement in movement_placeholders.items():
                  text = text.replace(placeholder, movement)
              
              # æ¸…ç†æ ¼å¼
              text = re.sub(r'[ï¼Œ,]\s*[ï¼Œ,]', '', text)
              text = re.sub(r'^\s*[,\-ï¼Œã€‚ï¼!ï¼Ÿ?;ï¼›ã€]\s*', '', text)
              text = re.sub(r'\s*[,\-ï¼Œã€‚ï¼!ï¼Ÿ?;ï¼›ã€]\s*$', '', text)
              text = re.sub(r'\s+', ' ', text)
              
              return text.strip()
          
          def generate_clean_title(original_title, attributes):
              """ç”Ÿæˆæ¸…ç†åçš„æ ‡é¢˜"""
              if not original_title:
                  return "æ— æ ‡é¢˜"
              
              # åˆ é™¤å“ç‰Œä¿¡æ¯
              cleaned_text = remove_brand_info(original_title)
              
              # æ¸…ç†å±æ€§å€¼
              clean_attributes = {}
              for key, value in attributes.items():
                  clean_value = remove_brand_info(value)
                  if clean_value:
                      clean_key = remove_brand_info(key)
                      if clean_key:
                          clean_attributes[clean_key] = clean_value
              
              # ä¿å­˜ç»“æœ
              with open('cleaned_title.txt', 'w', encoding='utf-8') as f:
                  f.write(cleaned_text)
              
              with open('cleaned_attributes.json', 'w', encoding='utf-8') as f:
                  json.dump(clean_attributes, f, ensure_ascii=False, indent=2)
              
              with open('original_title.txt', 'w', encoding='utf-8') as f:
                  f.write(original_title)
              
              # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
              print("ğŸ“Š æ•°æ®å¤„ç†ç»Ÿè®¡:")
              print(f"   åŸå§‹æ ‡é¢˜: {original_title[:100]}...")
              print(f"   æ¸…ç†åæ ‡é¢˜: {cleaned_text[:100]}...")
              print(f"   å‘ç°å±æ€§æ•°é‡: {len(clean_attributes)}")
              
              # è¾“å‡ºå‰5ä¸ªå±æ€§
              if clean_attributes:
                  print("   å‰5ä¸ªå±æ€§:")
                  for i, (key, value) in enumerate(list(clean_attributes.items())[:5]):
                      print(f"     {i+1}. {key}: {value}")
              
              return cleaned_text
          
          # ä¸»å‡½æ•°
          try:
              html = read_html_file('page.html')
              print(f"ğŸ“„ è¯»å–HTMLæˆåŠŸï¼Œå¤§å°: {len(html)} å­—ç¬¦")
              
              if len(html) < 100:
                  print("âš ï¸  è­¦å‘Šï¼šHTMLå†…å®¹è¿‡å°‘ï¼Œå¯èƒ½æŠ“å–å¤±è´¥")
              
              original_title = extract_title(html)
              print(f"ğŸ“ æå–åˆ°æ ‡é¢˜: {original_title[:80]}...")
              
              attributes = extract_attributes(html)
              print(f"ğŸ”§ æå–åˆ°åŸå§‹å±æ€§æ•°é‡: {len(attributes)}")
              
              cleaned_title = generate_clean_title(original_title, attributes)
              print("âœ… æ•°æ®å¤„ç†å®Œæˆ")
              
          except Exception as e:
              print(f"âŒ æ•°æ®å¤„ç†å‡ºé”™: {str(e)}")
              # åˆ›å»ºç©ºæ–‡ä»¶é¿å…åç»­æ­¥éª¤å¤±è´¥
              with open('cleaned_title.txt', 'w', encoding='utf-8') as f:
                  f.write("æ•°æ®å¤„ç†å¤±è´¥")
              with open('cleaned_attributes.json', 'w', encoding='utf-8') as f:
                  json.dump({}, f)
              with open('original_title.txt', 'w', encoding='utf-8') as f:
                  f.write("æ•°æ®å¤„ç†å¤±è´¥")
              exit(1)
          EOF
          
          python process.py
          
      - name: ç¿»è¯‘æ‰€æœ‰å†…å®¹
        id: translate
        run: |
          echo "ğŸŒ å¼€å§‹ç¿»è¯‘å†…å®¹..."
          
          cat > translate.py << 'EOF'
          from googletrans import Translator
          import json
          import re
          import time
          
          def translate_text(text, src='zh-cn', dest='en', max_retries=3):
              """ç¿»è¯‘æ–‡æœ¬åˆ°è‹±æ–‡ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
              if not text or len(text.strip()) < 2:
                  return text
              
              for attempt in range(max_retries):
                  try:
                      translator = Translator()
                      translated = translator.translate(text, src=src, dest=dest)
                      result = translated.text
                      
                      # åŸºæœ¬æ¸…ç†
                      result = re.sub(r'\s+', ' ', result)
                      result = result.strip()
                      
                      return result
                  except Exception as e:
                      if attempt < max_retries - 1:
                          print(f"âš ï¸  ç¿»è¯‘é‡è¯• {attempt+1}/{max_retries}: {str(e)[:50]}...")
                          time.sleep(1)
                      else:
                          print(f"âŒ ç¿»è¯‘å¤±è´¥: {str(e)}")
                          return text
              
              return text
          
          def translate_attributes(attributes):
              """ç¿»è¯‘æ‰€æœ‰å±æ€§"""
              if not attributes:
                  print("âš ï¸  æ— å±æ€§éœ€è¦ç¿»è¯‘")
                  return {}
                  
              translated = {}
              
              # å¸¸è§å±æ€§é”®åç¿»è¯‘æ˜ å°„
              key_mapping = {
                  'æœºèŠ¯ç±»å‹': 'Movement',
                  'æœºèŠ¯': 'Movement',
                  'å‹å·': 'Model',
                  'è¡¨å¸¦æè´¨': 'Strap Material',
                  'è¡¨å£³æè´¨': 'Case Material',
                  'è¡¨ç›˜æè´¨': 'Dial Material',
                  'è¡¨é•œæè´¨': 'Crystal Material',
                  'è¡¨æ‰£': 'Clasp',
                  'è¡¨å¾„': 'Case Diameter',
                  'åšåº¦': 'Thickness',
                  'é˜²æ°´': 'Water Resistance',
                  'åŠŸèƒ½': 'Functions',
                  'é€‚ç”¨äººç¾¤': 'For',
                  'é£æ ¼': 'Style',
                  'é¢œè‰²': 'Color',
                  'è¡¨å¸¦é¢œè‰²': 'Strap Color',
                  'è¡¨ç›˜é¢œè‰²': 'Dial Color',
                  'äº§åœ°': 'Origin',
                  'å“ç‰Œ': 'Brand',
                  'é‡é‡': 'Weight',
                  'åŒ…è£…': 'Package',
                  'é…ä»¶': 'Accessories',
                  'ä¿ä¿®': 'Warranty',
                  'ç‰¹ç‚¹': 'Features',
                  'æè´¨': 'Material',
                  'æ¬¾å¼': 'Style',
                  'ç±»å‹': 'Type',
                  'å°ºå¯¸': 'Size',
                  'ç”µæ± ': 'Battery',
                  'æœºèŠ¯äº§åœ°': 'Movement Origin',
                  'è¡¨å£³': 'Case',
                  'è¡¨å¸¦': 'Strap',
                  'è¡¨ç›˜': 'Dial',
                  'è¡¨é•œ': 'Crystal',
                  'å¤œå…‰': 'Luminous',
                  'æ—¥å†': 'Calendar',
                  'æ˜ŸæœŸ': 'Week',
                  'æœˆç›¸': 'Moon Phase',
                  'è®¡æ—¶': 'Chronograph',
                  'å¤ªé˜³èƒ½': 'Solar',
                  'è‡ªåŠ¨ä¸Šé“¾': 'Automatic',
                  'çŸ³è‹±': 'Quartz',
                  'æœºæ¢°': 'Mechanical',
              }
              
              print(f"ğŸ—‚ï¸  å¼€å§‹ç¿»è¯‘ {len(attributes)} ä¸ªå±æ€§...")
              for i, (key, value) in enumerate(attributes.items()):
                  # ç¿»è¯‘é”®
                  en_key = key_mapping.get(key, translate_text(key))
                  
                  # ç¿»è¯‘å€¼
                  en_value = translate_text(value)
                  
                  translated[en_key] = en_value
                  
                  # è¿›åº¦æ˜¾ç¤º
                  if (i + 1) % 5 == 0 or i == len(attributes) - 1:
                      print(f"   âœ“ å·²ç¿»è¯‘ {i+1}/{len(attributes)} ä¸ªå±æ€§")
              
              return translated
          
          try:
              # è¯»å–æ•°æ®
              with open('cleaned_title.txt', 'r', encoding='utf-8') as f:
                  cleaned_title = f.read().strip()
              
              with open('cleaned_attributes.json', 'r', encoding='utf-8') as f:
                  cleaned_attrs = json.load(f)
              
              with open('original_title.txt', 'r', encoding='utf-8') as f:
                  original_title = f.read().strip()
              
              print("ğŸ“– è¯»å–æ•°æ®å®Œæˆ")
              print(f"   åŸå§‹æ ‡é¢˜: {original_title[:80]}...")
              print(f"   æ¸…ç†åæ ‡é¢˜: {cleaned_title[:80]}...")
              print(f"   å¾…ç¿»è¯‘å±æ€§æ•°é‡: {len(cleaned_attrs)}")
              
              # ç¿»è¯‘æ ‡é¢˜
              print("ğŸ”  ç¿»è¯‘æ ‡é¢˜...")
              english_title = translate_text(cleaned_title)
              print(f"   âœ“ æ ‡é¢˜ç¿»è¯‘å®Œæˆ: {english_title[:80]}...")
              
              # ç¿»è¯‘å±æ€§
              english_attributes = translate_attributes(cleaned_attrs)
              
              # ä¿å­˜ç»“æœ
              with open('english_title.txt', 'w', encoding='utf-8') as f:
                  f.write(english_title)
              
              with open('english_attributes.json', 'w', encoding='utf-8') as f:
                  json.dump(english_attributes, f, ensure_ascii=False, indent=2)
              
              # ç”ŸæˆæŠ¥å‘Š
              report = {
                  'url': '${{ github.event.inputs.url }}',
                  'original_title': original_title,
                  'cleaned_title': cleaned_title,
                  'english_title': english_title,
                  'attributes_count': len(english_attributes),
                  'attributes': english_attributes
              }
              
              with open('report.json', 'w', encoding='utf-8') as f:
                  json.dump(report, f, ensure_ascii=False, indent=2)
              
              # ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š
              with open('report.md', 'w', encoding='utf-8') as f:
                  f.write(f'''# ğŸ›’ å•†å“ç¿»è¯‘æŠ¥å‘Š
                  
                  ## ğŸ“ åŸºæœ¬ä¿¡æ¯
                  - **å•†å“URL**: `{report['url']}`
                  - **å¤„ç†æ—¶é—´**: `$(date '+%Y-%m-%d %H:%M:%S')`
                  - **å±æ€§æ€»æ•°**: **{report['attributes_count']}**
                  
                  ## ğŸ“ æ ‡é¢˜ç¿»è¯‘
                  | ç±»å‹ | å†…å®¹ |
                  |------|------|
                  | åŸå§‹æ ‡é¢˜ | {report['original_title'][:200]} |
                  | æ¸…ç†åæ ‡é¢˜ | {report['cleaned_title'][:200]} |
                  | **è‹±æ–‡æ ‡é¢˜** | **{report['english_title'][:200]}** |
                  
                  ## ğŸ“Š å±æ€§åˆ—è¡¨
                  | åºå· | å±æ€§å | è‹±æ–‡ç¿»è¯‘ |
                  |------|--------|----------|''')
                  
                  for i, (key, value) in enumerate(english_attributes.items()):
                      f.write(f'\n| {i+1} | {key} | {value} |')
                  
                  if not english_attributes:
                      f.write('\n| - | æ— å±æ€§ä¿¡æ¯ | - |')
              
              print("\n" + "="*60)
              print("âœ… ç¿»è¯‘å®Œæˆ")
              print("="*60)
              print(f"ğŸ“Œ åŸå§‹æ ‡é¢˜: {original_title[:100]}...")
              print(f"ğŸŒ è‹±æ–‡æ ‡é¢˜: {english_title[:100]}...")
              print(f"ğŸ“Š å±æ€§æ•°é‡: {len(english_attributes)}")
              
              if english_attributes:
                  print("\nğŸ“‹ ç¿»è¯‘åçš„å±æ€§é¢„è§ˆ:")
                  for i, (key, value) in enumerate(list(english_attributes.items())[:10]):
                      print(f"   {i+1:2d}. {key[:20]:20} : {value[:50]}")
                  if len(english_attributes) > 10:
                      print(f"   ... è¿˜æœ‰ {len(english_attributes)-10} ä¸ªå±æ€§")
              
          except Exception as e:
              print(f"âŒ ç¿»è¯‘è¿‡ç¨‹å‡ºé”™: {str(e)}")
              # åˆ›å»ºç©ºæ–‡ä»¶é¿å…åç»­æ­¥éª¤å¤±è´¥
              with open('english_title.txt', 'w', encoding='utf-8') as f:
                  f.write("ç¿»è¯‘å¤±è´¥")
              with open('english_attributes.json', 'w', encoding='utf-8') as f:
                  json.dump({"error": str(e)}, f)
              exit(1)
          EOF
          
          python translate.py
          
      - name: åˆ›å»ºç»“æœæ‘˜è¦
        run: |
          echo "ğŸ“„ ç”Ÿæˆç»“æœæ‘˜è¦..."
          
          cat > summary.txt << 'EOF'
          ============================================================
                              ğŸ›’ å•†å“ç¿»è¯‘ç»“æœæ‘˜è¦
          ============================================================
          
          å¤„ç†URL: ${{ github.event.inputs.url }}
          å¤„ç†æ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')
          
          ğŸ“Œ æ ‡é¢˜ä¿¡æ¯:
          ------------------------------
          åŸå§‹æ ‡é¢˜: $(cat original_title.txt | head -c 200)
          
          è‹±æ–‡æ ‡é¢˜: $(cat english_title.txt | head -c 200)
          
          ğŸ“Š å±æ€§ç»Ÿè®¡:
          ------------------------------
          å±æ€§æ€»æ•°: $(python -c "import json; data = json.load(open('english_attributes.json')); print(len(data))")
          
          ğŸ“‹ å±æ€§é¢„è§ˆ:
          ------------------------------
          EOF
          
          # æ·»åŠ å±æ€§é¢„è§ˆ
          python -c "
          import json
          data = json.load(open('english_attributes.json'))
          count = 0
          for k, v in data.items():
              if count < 10:
                  print(f'{count+1:2d}. {k[:20]:20} : {v[:50]}')
                  count += 1
          " >> summary.txt
          
          echo "
          ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:
          ------------------------------
          1. original_title.txt      - åŸå§‹ä¸­æ–‡æ ‡é¢˜
          2. cleaned_title.txt       - æ¸…ç†åçš„ä¸­æ–‡æ ‡é¢˜
          3. english_title.txt       - ç¿»è¯‘åçš„è‹±æ–‡æ ‡é¢˜
          4. english_attributes.json - ç¿»è¯‘åçš„å±æ€§(JSONæ ¼å¼)
          5. report.json             - å®Œæ•´æŠ¥å‘Š(JSONæ ¼å¼)
          6. report.md               - Markdownæ ¼å¼æŠ¥å‘Š
          7. summary.txt             - æœ¬æ‘˜è¦æ–‡ä»¶
          
          ============================================================
          " >> summary.txt
          
          # æ˜¾ç¤ºæ‘˜è¦
          cat summary.txt
          
      - name: ä¸Šä¼ ç»“æœ
        uses: actions/upload-artifact@v4
        with:
          name: å•†å“ç¿»è¯‘ç»“æœ
          path: |
            original_title.txt
            cleaned_title.txt
            english_title.txt
            english_attributes.json
            report.json
            report.md
            summary.txt
          
      - name: æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        run: |
          echo ""
          echo "="*60
          echo "ğŸ‰ å•†å“ç¿»è¯‘å¤„ç†å®Œæˆï¼"
          echo "="*60
          echo ""
          
          # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
          echo "ğŸ“Œ å¤„ç†ç»“æœæ¦‚è¦:"
          echo "----------------------------------------"
          echo "ğŸ›’ å•†å“URL: ${{ github.event.inputs.url }}"
          echo ""
          echo "ğŸ“ è‹±æ–‡æ ‡é¢˜:"
          echo "   $(cat english_title.txt | head -c 150)"
          echo ""
          
          # æ˜¾ç¤ºå±æ€§æ•°é‡
          ATTRIBUTE_COUNT=$(python -c "import json; data=json.load(open('english_attributes.json')); print(len(data))")
          echo "ğŸ“Š å±æ€§ç»Ÿè®¡:"
          echo "   å‘ç°å±æ€§æ•°é‡: $ATTRIBUTE_COUNT ä¸ª"
          echo ""
          
          # æ˜¾ç¤ºéƒ¨åˆ†å±æ€§
          if [ $ATTRIBUTE_COUNT -gt 0 ]; then
            echo "ğŸ“‹ éƒ¨åˆ†å±æ€§é¢„è§ˆ:"
            python -c "
            import json
            data = json.load(open('english_attributes.json'))
            for i, (k, v) in enumerate(list(data.items())[:5]):
                print(f'   {i+1}. {k[:15]:15} : {v[:40]}')
            "
            if [ $ATTRIBUTE_COUNT -gt 5 ]; then
              echo "   ... è¿˜æœ‰ $((ATTRIBUTE_COUNT - 5)) ä¸ªå±æ€§"
            fi
            echo ""
          fi
          
          echo "ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœ:"
          echo "   è¯·åœ¨å³ä¾§ã€Artifactsã€‘åŒºåŸŸä¸‹è½½ã€å•†å“ç¿»è¯‘ç»“æœã€‘"
          echo ""
          echo "ğŸ“ ä¸‹è½½åŒ…åŒ…å«:"
          echo "   â€¢ english_title.txt       - è‹±æ–‡æ ‡é¢˜"
          echo "   â€¢ english_attributes.json - æ‰€æœ‰å±æ€§ç¿»è¯‘"
          echo "   â€¢ report.md               - å®Œæ•´MarkdownæŠ¥å‘Š"
          echo "   â€¢ å…¶ä»–è¯¦ç»†æ–‡ä»¶..."
          echo ""
          echo "="*60
          echo "âœ… å¤„ç†å®Œæˆï¼"
          echo "="*60
